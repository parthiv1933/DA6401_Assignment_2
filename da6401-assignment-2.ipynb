{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!gdown --id 1eSo7XcOuW1BlLLt4YT5Vo-gK1FgR8xMU","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip -q nature_12K.zip","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"https://drive.google.com/file/d/1eSo7XcOuW1BlLLt4YT5Vo-gK1FgR8xMU/view?usp=sharing","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn import Module, ReLU, Conv2d, Linear, MaxPool2d, LogSoftmax, NLLLoss, Dropout, BatchNorm2d, LeakyReLU, GELU, SELU, Mish\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom torch import flatten, float, no_grad\nfrom torch.optim import Adam\nimport torch\nimport wandb\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:27.593169Z","iopub.execute_input":"2025-04-18T12:19:27.593741Z","iopub.status.idle":"2025-04-18T12:19:29.642866Z","shell.execute_reply.started":"2025-04-18T12:19:27.593714Z","shell.execute_reply":"2025-04-18T12:19:29.642143Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"PARAMETERS = {\n    'data_augmentation': True,\n    'batch_normalization': False,\n    'filters': 64, # no. of filters in first layer\n    'filter_org': 'half', # 'half', 'double'\n    'dropout': 0.2,\n    'activation': 'relu',\n    'train_data_dir': \"/kaggle/working/inaturalist_12K/train\",\n    'test_data_dir': \"/kaggle/working/inaturalist_12K/val\",\n    'batch_size': 64,\n    'learning_rate': 0.001,\n    'epochs': 25,\n    'dim': 256,\n    'conv_kernel_size': 3,\n    'dense_neurons': 1000\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:32.644347Z","iopub.execute_input":"2025-04-18T12:19:32.644886Z","iopub.status.idle":"2025-04-18T12:19:32.649352Z","shell.execute_reply.started":"2025-04-18T12:19:32.644858Z","shell.execute_reply":"2025-04-18T12:19:32.648550Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"CLASSES = {\n    0:'Amphibia',\n    1:'Animalia',\n    2:'Arachnida',\n    3:'Aves',\n    4:'Fungi',\n    5:'Insecta',\n    6:'Mammalia',\n    7:'Mollusca',\n    8:'Plantae',\n    9:'Reptilia'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:35.230250Z","iopub.execute_input":"2025-04-18T12:19:35.230946Z","iopub.status.idle":"2025-04-18T12:19:35.234682Z","shell.execute_reply.started":"2025-04-18T12:19:35.230922Z","shell.execute_reply":"2025-04-18T12:19:35.233877Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def get_data(param, type):\n    if(type.lower() == 'train'):\n        if param['data_augmentation']:\n            transform = transforms.Compose([\n                transforms.RandomHorizontalFlip(p=0.3),\n                transforms.RandomRotation(degrees=12),\n                transforms.Resize((param['dim'],param['dim'])),\n                transforms.ToTensor(), \n                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n            ])\n        else:\n            transform = transforms.Compose([\n                transforms.Resize((param['dim'],param['dim'])),\n                transforms.ToTensor(), \n                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n            ])\n\n        tdataset = datasets.ImageFolder(root=param['train_data_dir'], transform=transform)\n        total = len(tdataset)\n        train_sample = math.ceil(total*(0.8))\n        val_sample = total-train_sample\n        # print(total, train_sample, val_sample)\n        train_dataset, validation_dataset = torch.utils.data.random_split(tdataset, [train_sample, val_sample])\n        train_dataloader = DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True)\n        validation_dataloader = DataLoader(validation_dataset, batch_size=param['batch_size'], shuffle=False)\n        return train_dataloader, validation_dataloader\n    \n    else:\n        transform = transforms.Compose([\n            transforms.Resize((param['dim'],param['dim'])),\n            transforms.ToTensor(), \n            transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n        ])\n        test_dataset = datasets.ImageFolder(root=param['test_data_dir'], transform=transform)\n        test_dataloader = DataLoader(test_dataset, batch_size=param['batch_size'])\n        return test_dataloader\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:38.150162Z","iopub.execute_input":"2025-04-18T12:19:38.150925Z","iopub.status.idle":"2025-04-18T12:19:38.158912Z","shell.execute_reply.started":"2025-04-18T12:19:38.150898Z","shell.execute_reply":"2025-04-18T12:19:38.158091Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class CNN(Module):\n    def __init__(self, param):\n        super(CNN, self).__init__()\n        self.param=param\n        self.data_augmentation = param['data_augmentation']\n        self.dropout = param['dropout']\n        self.act = self.getActivation(param['activation'])\n        self.filters = self.filter_logic(param['filters'], param['filter_org'])\n        self.conv_ks = param['conv_kernel_size']\n        self.dim = param['dim']\n        self.bn = param['batch_normalization']\n        self.dense_neurons = param['dense_neurons']\n\n\n        ####### Layer 1 #######\n        curr_dim = self.dim\n        self.conv1 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=3, out_channels=self.filters[0])\n        curr_dim -= (self.conv_ks-1)\n        self.act1 = self.act\n        if(self.bn): self.bn1 = BatchNorm2d(self.filters[0])\n        self.pool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout1 = Dropout(p=self.dropout)\n\n        ####### Layer 2 #######\n        self.conv2 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[0], out_channels=self.filters[1])\n        curr_dim -= (self.conv_ks-1)\n        self.act2 = self.act\n        if(self.bn): self.bn2 = BatchNorm2d(self.filters[1])\n        self.pool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout2 = Dropout(p=self.dropout)\n\n        ####### Layer 3 #######\n        self.conv3 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[1], out_channels=self.filters[2])\n        curr_dim -= (self.conv_ks-1)\n        self.act3 = self.act\n        if(self.bn): self.bn3 = BatchNorm2d(self.filters[2])\n        self.pool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout3 = Dropout(p=self.dropout)\n\n        ####### Layer 4 #######\n        self.conv4 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[2], out_channels=self.filters[3])\n        curr_dim -= (self.conv_ks-1)\n        self.act4 = self.act\n        if(self.bn): self.bn4 = BatchNorm2d(self.filters[3])\n        self.pool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout4 = Dropout(p=self.dropout)\n\n\n        ####### Layer 5 #######\n        self.conv5 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[3], out_channels=self.filters[4])\n        curr_dim -= (self.conv_ks-1)\n        self.act5 = self.act\n        if(self.bn): self.bn5 = BatchNorm2d(self.filters[4])\n        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout5 = Dropout(p=self.dropout)\n\n    \n        ####### Fully Connected Layer #######\n        self.dense_neurons = curr_dim * curr_dim * self.filters[4]\n        self.fc1 = Linear(in_features=(curr_dim * curr_dim * self.filters[4]), out_features=self.dense_neurons)  # How to calculate dimension of filters at previous level\n        self.act6 = self.act\n        self.dropout6 = Dropout(p=0.5)\n        \n\n        ####### Output Layer #######\n        self.out = Linear(in_features=self.dense_neurons, out_features=10)\n        self.act7 = LogSoftmax(dim=1)\n\n\n    def getActivation(self, act):\n        act = act.lower()\n        if(act == 'relu'):\n            return ReLU()\n        elif(act == 'leakyrelu'):\n            return LeakyReLU()\n        elif(act == 'gelu'):\n            return GELU()\n        elif(act == 'selu'):\n            return SELU()\n        elif(act == 'mish'):\n            return Mish()\n    \n\n    def filter_logic(self, filter, org):\n        level = []\n        org = org.lower()\n        if org == 'same':\n            level = [filter for i in range(5)]\n        elif org == 'double':\n            level = [filter*pow(2,i) for i in range(5)]\n        elif org == 'half':\n            level = [max(filter//pow(2,i),1) for i in range(5)]\n        return level\n\n    \n\n    def forward(self, r):\n\n        r=self.conv1(r)\n        r=self.act1(r)\n        if(self.bn): r=self.bn1(r)\n        r=self.pool1(r)\n        r=self.dropout1(r)\n\n        r=self.conv2(r)\n        r=self.act2(r)\n        if(self.bn): r=self.bn2(r)\n        r=self.pool2(r)\n        r=self.dropout2(r)\n\n        r=self.conv3(r)\n        r=self.act3(r)\n        if(self.bn): r=self.bn3(r)\n        r=self.pool3(r)\n        r=self.dropout3(r)\n\n        r=self.conv4(r)\n        r=self.act4(r)\n        if(self.bn): r=self.bn4(r)\n        r=self.pool4(r)\n        r=self.dropout4(r)\n\n        r=self.conv5(r)\n        r=self.act5(r)\n        if(self.bn): r=self.bn5(r)\n        r=self.pool5(r)\n        r=self.dropout5(r)\n\n        r=flatten(r,1)\n        r=self.fc1(r)\n        r=self.act6(r)\n        r=self.dropout6(r)\n        \n        r=self.out(r)\n        output=self.act7(r)\n\n        return output\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:44.858893Z","iopub.execute_input":"2025-04-18T12:19:44.859678Z","iopub.status.idle":"2025-04-18T12:19:44.876852Z","shell.execute_reply.started":"2025-04-18T12:19:44.859650Z","shell.execute_reply":"2025-04-18T12:19:44.876221Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# # For personal debug use\n# def train(param):\n#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#     model = CNN(param).to(device)\n#     optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n#     loss_function = NLLLoss()\n#     train_data_loader, validation_data_loader = get_data(param, 'train')\n    \n\n#     for epo in range(param['epochs']):\n#         model.train()\n#         totalTrainLoss = 0\n#         totalValLoss = 0\n#         trainCorrect = 0\n#         valCorrect = 0\n#         train_counter=0\n#         validation_counter=0\n#         for (image, label) in train_data_loader:\n#             (image, label) = (image.to(device), label.to(device))\n#             prediction = model(image)\n#             loss = loss_function(prediction, label)\n            \n#             optimizer.zero_grad()\n#             loss.backward()\n#             optimizer.step()\n            \n#             totalTrainLoss += loss\n#             trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n#             train_counter+=1\n#             # print(train_counter)\n        \n#         with no_grad():\n#             model.eval()\n#             for (image, label) in validation_data_loader:\n#                 (image, label) = (image.to(device), label.to(device))\n#                 pred = model(image)\n#                 totalValLoss += loss_function(pred, label)\n#                 valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n#                 validation_counter+=1\n\n#         print(f\"Epochs --> {epo}\")\n#         print(f\"Train Loss --> {(totalTrainLoss/train_counter).cpu().detach().numpy()}\")\n#         print(f\"Train Accuracy --> {trainCorrect/len(train_data_loader.dataset)}\")\n#         print(f\"Validation Loss --> {(totalValLoss/validation_counter).cpu().detach().numpy()}\")\n#         print(f\"Validation Accuracy --> {valCorrect/len(validation_data_loader.dataset)}\")\n#         print(\"##########################################################################################\")\n    \n#     return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mdl = train(PARAMETERS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# test_data_loader = get_data(PARAMETERS, 'test')\n# tstCorrect = 0\n# tstCounter = 0\n# y = []\n# y_pred = []\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# with no_grad():\n#     mdl.eval()\n#     for (image, label) in test_data_loader:\n#         (image, label) = (image.to(device), label.to(device))\n#         pred = mdl(image)\n#         y.extend(label.tolist())\n#         y_pred.extend(pred.argmax(1).tolist())\n#         # print(pred)\n#         tstCorrect += (pred.argmax(1) == label).type(float).sum().item()\n#         tstCounter+=PARAMETERS['batch_size']\n\n# print(tstCorrect)\n# print(tstCounter)\n# print((tstCorrect/tstCounter)*100)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## for wandb sweeps\ndef train():\n    wandb.init()\n    param = wandb.config\n    wandb.run.name = f'fltr_{param.filters}_fltrOrg_{param.filter_org}_dataAug_{param.data_augmentation}_batchNorm_{param.batch_normalization}_act_{param.activation}_batchSz_{param.batch_size}'\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = CNN(param).to(device)\n    optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n    loss_function = NLLLoss()\n    train_data_loader, validation_data_loader = get_data(param, 'train')\n    \n\n    for epo in range(param['epochs']):\n        model.train()\n        totalTrainLoss = 0\n        totalValLoss = 0\n        trainCorrect = 0\n        valCorrect = 0\n        train_counter=0\n        validation_counter=0\n        for (image, label) in train_data_loader:\n            (image, label) = (image.to(device), label.to(device))\n            prediction = model(image)\n            loss = loss_function(prediction, label)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            totalTrainLoss += loss\n            trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n            train_counter+=1\n          \n        \n        with no_grad():\n            model.eval()\n            for (image, label) in validation_data_loader:\n                (image, label) = (image.to(device), label.to(device))\n                pred = model(image)\n                totalValLoss += loss_function(pred, label)\n                valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n                validation_counter+=1\n\n        tr_ls = (totalTrainLoss/train_counter).cpu().detach().numpy()\n        tr_acc = trainCorrect/len(train_data_loader.dataset)\n        val_ls = (totalValLoss/validation_counter).cpu().detach().numpy()\n        val_acc = valCorrect/len(validation_data_loader.dataset)\n        print(f\"Epoch --> {epo}\")\n        print(f\"Train Loss --> {tr_ls}\")\n        print(f\"Train Accuracy --> {tr_acc}\")\n        print(f\"Validation Loss --> {val_ls}\")\n        print(f\"Validation Accuracy --> {val_acc}\")\n        \n        lg={\n            'epoch': epo+1,\n            'tr_accuracy': tr_acc,\n            'val_accuracy': val_acc,\n            'tr_loss': tr_ls,\n            'val_loss': val_ls\n        }\n        wandb.log(lg)\n\n        # return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:53.762687Z","iopub.execute_input":"2025-04-18T12:19:53.763248Z","iopub.status.idle":"2025-04-18T12:19:53.771767Z","shell.execute_reply.started":"2025-04-18T12:19:53.763223Z","shell.execute_reply":"2025-04-18T12:19:53.770943Z"}},"outputs":[],"execution_count":8},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\n\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:19:59.592438Z","iopub.execute_input":"2025-04-18T12:19:59.592702Z","iopub.status.idle":"2025-04-18T12:19:59.766229Z","shell.execute_reply.started":"2025-04-18T12:19:59.592684Z","shell.execute_reply":"2025-04-18T12:19:59.765530Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# sweep_config = {\n#   \"method\": \"bayes\", \n#   \"name\": \"Q2 Sweep\",\n#   \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"},\n#   \"parameters\": {\n#     \"data_augmentation\":{\"values\": [True,False]},  # List of boolean values\n#     \"batch_normalization\":{\"values\": [True,False]},  # List of boolean values\n#     \"filters\":{\"values\": [32]},  # List of filter values for first layer\n#     \"filter_org\":{\"values\": [\"same\",\"half\",\"double\"]},  # List of filter organization options.. , \"half\", \"double\"\n#     \"dropout\":{\"values\": [0.2,0.3]},  # Dropout rates\n#     \"activation\":{\"values\": [\"relu\",\"leakyrelu\",\"gelu\",\"mish\",\"selu\"]},  # Activation functions... , \"relu\", \"leaky_relu\"\n#     \"batch_size\":{\"values\": [32]},\n#     \"learning_rate\":{\"values\": [0.001,0.0001]},\n#     \"epochs\":{\"values\": [10]},\n#     \"dim\":{\"values\": [256]},\n#     \"conv_kernel_size\":{\"values\": [3,5]},\n#     \"dense_neurons\":{\"values\": [512]},\n#     \"train_data_dir\":{\"values\": [\"/kaggle/working/inaturalist_12K/train\"]},\n#     \"test_data_dir\":{\"values\": [\"/kaggle/working/inaturalist_12K/val\"]}\n#   }\n# }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T17:55:15.008918Z","iopub.execute_input":"2025-04-17T17:55:15.009209Z","iopub.status.idle":"2025-04-17T17:55:15.014910Z","shell.execute_reply.started":"2025-04-17T17:55:15.009189Z","shell.execute_reply":"2025-04-17T17:55:15.014095Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"sweep_config = {\n  \"method\": \"bayes\", \n  \"name\": \"Q2 Sweep(modified run for find accurate model)\",\n  \"metric\": {\"goal\": \"maximize\", \"name\": \"val_accuracy\"},\n  \"parameters\": {\n    \"data_augmentation\":{\"values\": [True]},  # List of boolean values\n    \"batch_normalization\":{\"values\": [True]},  # List of boolean values\n    \"filters\":{\"values\": [32]},  # List of filter values for first layer\n    \"filter_org\":{\"values\": [\"double\"]},  # List of filter organization options.. , \"half\", \"double\"\n    \"dropout\":{\"values\": [0.2]},  # Dropout rates\n    \"activation\":{\"values\": [\"relu\"]},  # Activation functions... , \"relu\", \"leaky_relu\"\n    \"batch_size\":{\"values\": [32]},\n    \"learning_rate\":{\"values\": [0.0001]},\n    \"epochs\":{\"values\": [15]},\n    \"dim\":{\"values\": [256]},\n    \"conv_kernel_size\":{\"values\": [3]},\n    \"dense_neurons\":{\"values\": [128]},\n    \"train_data_dir\":{\"values\": [\"/kaggle/working/inaturalist_12K/train\"]},\n    \"test_data_dir\":{\"values\": [\"/kaggle/working/inaturalist_12K/val\"]}\n  }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:43:50.940761Z","iopub.execute_input":"2025-04-18T15:43:50.941510Z","iopub.status.idle":"2025-04-18T15:43:50.954270Z","shell.execute_reply.started":"2025-04-18T15:43:50.941486Z","shell.execute_reply":"2025-04-18T15:43:50.953339Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"wandb.login(key=\"b8d44a4abbab8753e976a6e5ab717fd669ba99a2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T12:23:48.521256Z","iopub.execute_input":"2025-04-18T12:23:48.521951Z","iopub.status.idle":"2025-04-18T12:23:54.477846Z","shell.execute_reply.started":"2025-04-18T12:23:48.521925Z","shell.execute_reply":"2025-04-18T12:23:54.477068Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs24m030\u001b[0m (\u001b[33mcs24m030-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# wandb.init()\nsweep_id = wandb.sweep(sweep_config, project=\"DA6401_A2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:43:54.423526Z","iopub.execute_input":"2025-04-18T15:43:54.423774Z","iopub.status.idle":"2025-04-18T15:43:54.878218Z","shell.execute_reply.started":"2025-04-18T15:43:54.423757Z","shell.execute_reply":"2025-04-18T15:43:54.877432Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ju8yongi\nSweep URL: https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/sweeps/ju8yongi\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"wandb.agent(sweep_id, function=train, count=1)\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T15:44:08.177731Z","iopub.execute_input":"2025-04-18T15:44:08.177993Z","iopub.status.idle":"2025-04-18T16:21:35.009002Z","shell.execute_reply.started":"2025-04-18T15:44:08.177974Z","shell.execute_reply":"2025-04-18T16:21:35.008409Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fc9g4ssv with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_normalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_kernel_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_augmentation: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_neurons: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: double\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttest_data_dir: /kaggle/working/inaturalist_12K/val\n\u001b[34m\u001b[1mwandb\u001b[0m: \ttrain_data_dir: /kaggle/working/inaturalist_12K/train\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_154414-fc9g4ssv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/runs/fc9g4ssv' target=\"_blank\">copper-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/sweeps/ju8yongi' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/sweeps/ju8yongi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/sweeps/ju8yongi' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/sweeps/ju8yongi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/runs/fc9g4ssv' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/runs/fc9g4ssv</a>"},"metadata":{}},{"name":"stdout","text":"Epoch --> 0\nTrain Loss --> 2.7439067363739014\nTrain Accuracy --> 0.2265\nValidation Loss --> 5.075695514678955\nValidation Accuracy --> 0.17058529264632316\nEpoch --> 1\nTrain Loss --> 2.0774593353271484\nTrain Accuracy --> 0.288625\nValidation Loss --> 5.123627662658691\nValidation Accuracy --> 0.1645822911455728\nEpoch --> 2\nTrain Loss --> 1.9868208169937134\nTrain Accuracy --> 0.309\nValidation Loss --> 5.873669147491455\nValidation Accuracy --> 0.17708854427213608\nEpoch --> 3\nTrain Loss --> 1.895666480064392\nTrain Accuracy --> 0.344125\nValidation Loss --> 6.5538763999938965\nValidation Accuracy --> 0.16258129064532267\nEpoch --> 4\nTrain Loss --> 1.8395497798919678\nTrain Accuracy --> 0.366\nValidation Loss --> 6.094595909118652\nValidation Accuracy --> 0.15807903951975988\nEpoch --> 5\nTrain Loss --> 1.7673914432525635\nTrain Accuracy --> 0.38875\nValidation Loss --> 4.946824073791504\nValidation Accuracy --> 0.16808404202101052\nEpoch --> 6\nTrain Loss --> 1.6752547025680542\nTrain Accuracy --> 0.4235\nValidation Loss --> 4.707128524780273\nValidation Accuracy --> 0.19859929964982492\nEpoch --> 7\nTrain Loss --> 1.609400987625122\nTrain Accuracy --> 0.454375\nValidation Loss --> 4.139487266540527\nValidation Accuracy --> 0.192096048024012\nEpoch --> 8\nTrain Loss --> 1.4895681142807007\nTrain Accuracy --> 0.48675\nValidation Loss --> 4.344479084014893\nValidation Accuracy --> 0.19709854927463732\nEpoch --> 9\nTrain Loss --> 1.3443905115127563\nTrain Accuracy --> 0.53375\nValidation Loss --> 3.982863426208496\nValidation Accuracy --> 0.2206103051525763\nEpoch --> 10\nTrain Loss --> 1.2092045545578003\nTrain Accuracy --> 0.5935\nValidation Loss --> 3.3150205612182617\nValidation Accuracy --> 0.2556278139069535\nEpoch --> 11\nTrain Loss --> 1.080609679222107\nTrain Accuracy --> 0.634125\nValidation Loss --> 3.1887247562408447\nValidation Accuracy --> 0.2926463231615808\nEpoch --> 12\nTrain Loss --> 0.9330504536628723\nTrain Accuracy --> 0.692625\nValidation Loss --> 3.0754752159118652\nValidation Accuracy --> 0.31765882941470736\nEpoch --> 13\nTrain Loss --> 0.8013684749603271\nTrain Accuracy --> 0.734375\nValidation Loss --> 3.9607765674591064\nValidation Accuracy --> 0.2816408204102051\nEpoch --> 14\nTrain Loss --> 0.6715842485427856\nTrain Accuracy --> 0.782\nValidation Loss --> 3.5791146755218506\nValidation Accuracy --> 0.32566283141570784\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>tr_accuracy</td><td>▁▂▂▂▃▃▃▄▄▅▆▆▇▇█</td></tr><tr><td>tr_loss</td><td>█▆▅▅▅▅▄▄▄▃▃▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▂▁▂▁▁▁▃▂▃▄▅▇█▆█</td></tr><tr><td>val_loss</td><td>▅▅▇█▇▅▄▃▄▃▁▁▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>tr_accuracy</td><td>0.782</td></tr><tr><td>tr_loss</td><td>0.67158</td></tr><tr><td>val_accuracy</td><td>0.32566</td></tr><tr><td>val_loss</td><td>3.57911</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fltr_32_fltrOrg_double_dataAug_True_batchNorm_True_act_relu_batchSz_32</strong> at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/runs/fc9g4ssv' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2/runs/fc9g4ssv</a><br> View project at: <a href='https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2' target=\"_blank\">https://wandb.ai/cs24m030-indian-institute-of-technology-madras/DA6401_A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_154414-fc9g4ssv/logs</code>"},"metadata":{}}],"execution_count":34}]}