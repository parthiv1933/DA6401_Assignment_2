{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!gdown --id 1eSo7XcOuW1BlLLt4YT5Vo-gK1FgR8xMU","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:43:19.378698Z","iopub.execute_input":"2025-04-17T14:43:19.379256Z","iopub.status.idle":"2025-04-17T14:44:15.578974Z","shell.execute_reply.started":"2025-04-17T14:43:19.379224Z","shell.execute_reply":"2025-04-17T14:44:15.577896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!unzip -q nature_12K.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T14:46:39.462084Z","iopub.execute_input":"2025-04-17T14:46:39.462395Z","iopub.status.idle":"2025-04-17T14:47:10.005226Z","shell.execute_reply.started":"2025-04-17T14:46:39.462368Z","shell.execute_reply":"2025-04-17T14:47:10.004284Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"https://drive.google.com/file/d/1eSo7XcOuW1BlLLt4YT5Vo-gK1FgR8xMU/view?usp=sharing","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn import Module, ReLU, Conv2d, Linear, MaxPool2d, LogSoftmax, NLLLoss, Dropout, BatchNorm2d, LeakyReLU, GELU, SELU, Mish\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom torch import flatten, float, no_grad\nfrom torch.optim import Adam\nimport torch\nimport wandb\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:02:57.741688Z","iopub.execute_input":"2025-04-17T15:02:57.741991Z","iopub.status.idle":"2025-04-17T15:02:57.747258Z","shell.execute_reply.started":"2025-04-17T15:02:57.741969Z","shell.execute_reply":"2025-04-17T15:02:57.746423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"PARAMETERS = {\n    'data_augmentation': True,\n    'batch_normalization': False,\n    'filters': 64, # no. of filters in first layer\n    'filter_org': 'half', # 'half', 'double'\n    'dropout': 0,\n    'activation': 'relu',\n    'train_data_dir': \"/kaggle/working/inaturalist_12K/train\",\n    'test_data_dir': \"/kaggle/working/inaturalist_12K/val\",\n    'batch_size': 64,\n    'learning_rate': 0.001,\n    'epochs': 25,\n    'dim': 256,\n    'conv_kernel_size': 3,\n    'dense_neurons': 1000\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:00.305838Z","iopub.execute_input":"2025-04-17T15:03:00.306162Z","iopub.status.idle":"2025-04-17T15:03:00.311228Z","shell.execute_reply.started":"2025-04-17T15:03:00.306140Z","shell.execute_reply":"2025-04-17T15:03:00.310326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"CLASSES = {\n    0:'Amphibia',\n    1:'Animalia',\n    2:'Arachnida',\n    3:'Aves',\n    4:'Fungi',\n    5:'Insecta',\n    6:'Mammalia',\n    7:'Mollusca',\n    8:'Plantae',\n    9:'Reptilia'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:02.266665Z","iopub.execute_input":"2025-04-17T15:03:02.267209Z","iopub.status.idle":"2025-04-17T15:03:02.271543Z","shell.execute_reply.started":"2025-04-17T15:03:02.267186Z","shell.execute_reply":"2025-04-17T15:03:02.270838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_data(param, type):\n    if(type.lower() == 'train'):\n        if param['data_augmentation']:\n            transform = transforms.Compose([\n                transforms.RandomHorizontalFlip(p=0.3),\n                transforms.RandomRotation(degrees=12),\n                transforms.Resize((param['dim'],param['dim'])),\n                transforms.ToTensor(), \n                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n            ])\n        else:\n            transform = transforms.Compose([\n                transforms.Resize((param['dim'],param['dim'])),\n                transforms.ToTensor(), \n                transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n            ])\n\n        tdataset = datasets.ImageFolder(root=param['train_data_dir'], transform=transform)\n        total = len(tdataset)\n        train_sample = math.ceil(total*(0.8))\n        val_sample = total-train_sample\n        # print(total, train_sample, val_sample)\n        train_dataset, validation_dataset = torch.utils.data.random_split(tdataset, [train_sample, val_sample])\n        train_dataloader = DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True)\n        validation_dataloader = DataLoader(validation_dataset, batch_size=param['batch_size'], shuffle=False)\n        return train_dataloader, validation_dataloader\n    \n    else:\n        transform = transforms.Compose([\n            transforms.Resize((param['dim'],param['dim'])),\n            transforms.ToTensor(), \n            transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])  \n        ])\n        test_dataset = datasets.ImageFolder(root=param['test_data_dir'], transform=transform)\n        test_dataloader = DataLoader(test_dataset, batch_size=param['batch_size'])\n        return test_dataloader\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:10.538292Z","iopub.execute_input":"2025-04-17T15:03:10.538595Z","iopub.status.idle":"2025-04-17T15:03:10.546928Z","shell.execute_reply.started":"2025-04-17T15:03:10.538572Z","shell.execute_reply":"2025-04-17T15:03:10.546090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CNN(Module):\n    def __init__(self, param):\n        super(CNN, self).__init__()\n        self.param=param\n        self.data_augmentation = param['data_augmentation']\n        self.dropout = param['dropout']\n        self.act = self.getActivation(param['activation'])\n        self.filters = self.filter_logic(param['filters'], param['filter_org'])\n        self.conv_ks = param['conv_kernel_size']\n        self.dim = param['dim']\n        self.bn = param['batch_normalization']\n        self.dense_neurons = param['dense_neurons']\n\n\n        ####### Layer 1 #######\n        curr_dim = self.dim\n        self.conv1 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=3, out_channels=self.filters[0])\n        curr_dim -= (self.conv_ks-1)\n        self.act1 = self.act\n        if(self.bn): self.bn1 = BatchNorm2d(self.filters[0])\n        self.pool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout1 = Dropout(p=self.dropout)\n\n        ####### Layer 2 #######\n        self.conv2 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[0], out_channels=self.filters[1])\n        curr_dim -= (self.conv_ks-1)\n        self.act2 = self.act\n        if(self.bn): self.bn2 = BatchNorm2d(self.filters[1])\n        self.pool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout2 = Dropout(p=self.dropout)\n\n        ####### Layer 3 #######\n        self.conv3 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[1], out_channels=self.filters[2])\n        curr_dim -= (self.conv_ks-1)\n        self.act3 = self.act\n        if(self.bn): self.bn3 = BatchNorm2d(self.filters[2])\n        self.pool3 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout3 = Dropout(p=self.dropout)\n\n        ####### Layer 4 #######\n        self.conv4 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[2], out_channels=self.filters[3])\n        curr_dim -= (self.conv_ks-1)\n        self.act4 = self.act\n        if(self.bn): self.bn4 = BatchNorm2d(self.filters[3])\n        self.pool4 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout4 = Dropout(p=self.dropout)\n\n\n        ####### Layer 5 #######\n        self.conv5 = Conv2d(kernel_size=(self.conv_ks,self.conv_ks), in_channels=self.filters[3], out_channels=self.filters[4])\n        curr_dim -= (self.conv_ks-1)\n        self.act5 = self.act\n        if(self.bn): self.bn5 = BatchNorm2d(self.filters[4])\n        self.pool5 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        curr_dim //= 2\n        self.dropout5 = Dropout(p=self.dropout)\n\n    \n        ####### Fully Connected Layer #######\n        self.dense_neurons = curr_dim * curr_dim * self.filters[4]\n        self.fc1 = Linear(in_features=(curr_dim * curr_dim * self.filters[4]), out_features=self.dense_neurons)  # How to calculate dimension of filters at previous level\n        self.act6 = self.act\n        self.dropout6 = Dropout(p=0.5)\n        \n\n        ####### Output Layer #######\n        self.out = Linear(in_features=self.dense_neurons, out_features=10)\n        self.act7 = LogSoftmax(dim=1)\n\n\n    def getActivation(self, act):\n        act = act.lower()\n        if(act == 'relu'):\n            return ReLU()\n        elif(act == 'leakyrelu'):\n            return LeakyReLU()\n        elif(act == 'gelu'):\n            return GELU()\n        elif(act == 'selu'):\n            return SELU()\n        elif(act == 'mish'):\n            return Mish()\n    \n\n    def filter_logic(self, filter, org):\n        level = []\n        org = org.lower()\n        if org == 'same':\n            level = [filter for i in range(5)]\n        elif org == 'double':\n            level = [filter*pow(2,i) for i in range(5)]\n        elif org == 'half':\n            level = [max(filter//pow(2,i),1) for i in range(5)]\n        return level\n\n    \n\n    def forward(self, r):\n\n        r=self.conv1(r)\n        r=self.act1(r)\n        if(self.bn): r=self.bn1(r)\n        r=self.pool1(r)\n        r=self.dropout1(r)\n\n        r=self.conv2(r)\n        r=self.act2(r)\n        if(self.bn): r=self.bn2(r)\n        r=self.pool2(r)\n        r=self.dropout2(r)\n\n        r=self.conv3(r)\n        r=self.act3(r)\n        if(self.bn): r=self.bn3(r)\n        r=self.pool3(r)\n        r=self.dropout3(r)\n\n        r=self.conv4(r)\n        r=self.act4(r)\n        if(self.bn): r=self.bn4(r)\n        r=self.pool4(r)\n        r=self.dropout4(r)\n\n        r=self.conv5(r)\n        r=self.act5(r)\n        if(self.bn): r=self.bn5(r)\n        r=self.pool5(r)\n        r=self.dropout5(r)\n\n        r=flatten(r,1)\n        r=self.fc1(r)\n        r=self.act6(r)\n        r=self.dropout6(r)\n        \n        r=self.out(r)\n        output=self.act7(r)\n\n        return output\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:13.373511Z","iopub.execute_input":"2025-04-17T15:03:13.373824Z","iopub.status.idle":"2025-04-17T15:03:13.393984Z","shell.execute_reply.started":"2025-04-17T15:03:13.373803Z","shell.execute_reply":"2025-04-17T15:03:13.393086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# For personal debug use\ndef train(param):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = CNN(param).to(device)\n    optimizer = Adam(model.parameters(), lr=param['learning_rate'])\n    loss_function = NLLLoss()\n    train_data_loader, validation_data_loader = get_data(param, 'train')\n    \n\n    for epo in range(param['epochs']):\n        model.train()\n        totalTrainLoss = 0\n        totalValLoss = 0\n        trainCorrect = 0\n        valCorrect = 0\n        train_counter=0\n        validation_counter=0\n        for (image, label) in train_data_loader:\n            (image, label) = (image.to(device), label.to(device))\n            prediction = model(image)\n            loss = loss_function(prediction, label)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            totalTrainLoss += loss\n            trainCorrect += (prediction.argmax(1) == label).type(float).sum().item()\n            train_counter+=1\n            # print(train_counter)\n        \n        with no_grad():\n            model.eval()\n            for (image, label) in validation_data_loader:\n                (image, label) = (image.to(device), label.to(device))\n                pred = model(image)\n                totalValLoss += loss_function(pred, label)\n                valCorrect += (pred.argmax(1) == label).type(float).sum().item()\n                validation_counter+=1\n\n        print(f\"Epochs --> {epo}\")\n        print(f\"Train Loss --> {(totalTrainLoss/train_counter).cpu().detach().numpy()}\")\n        print(f\"Train Accuracy --> {trainCorrect/len(train_data_loader.dataset)}\")\n        print(f\"Validation Loss --> {(totalValLoss/validation_counter).cpu().detach().numpy()}\")\n        print(f\"Validation Accuracy --> {valCorrect/len(validation_data_loader.dataset)}\")\n        print(\"##########################################################################################\")\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:18.888820Z","iopub.execute_input":"2025-04-17T15:03:18.889719Z","iopub.status.idle":"2025-04-17T15:03:18.897792Z","shell.execute_reply.started":"2025-04-17T15:03:18.889691Z","shell.execute_reply":"2025-04-17T15:03:18.896921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mdl = train(PARAMETERS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T15:03:22.576275Z","iopub.execute_input":"2025-04-17T15:03:22.576567Z","iopub.status.idle":"2025-04-17T15:59:43.682608Z","shell.execute_reply.started":"2025-04-17T15:03:22.576546Z","shell.execute_reply":"2025-04-17T15:59:43.681331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data_loader = get_data(PARAMETERS, 'test')\ntstCorrect = 0\ntstCounter = 0\ny = []\ny_pred = []\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nwith no_grad():\n    mdl.eval()\n    for (image, label) in test_data_loader:\n        (image, label) = (image.to(device), label.to(device))\n        pred = mdl(image)\n        y.extend(label.tolist())\n        y_pred.extend(pred.argmax(1).tolist())\n        # print(pred)\n        tstCorrect += (pred.argmax(1) == label).type(float).sum().item()\n        tstCounter+=PARAMETERS['batch_size']\n\nprint(tstCorrect)\nprint(tstCounter)\nprint((tstCorrect/tstCounter)*100)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}